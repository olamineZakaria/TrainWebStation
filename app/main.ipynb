{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import os\n",
    "import matplotlib\n",
    "from io import StringIO\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "class ANNRegressionModel:\n",
    "    def __init__(self, config_file):\n",
    "        self.model_info = self.extract_model_info(config_file)\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def extract_model_info(self, config_file):\n",
    "        # Define the regex patterns\n",
    "        patterns = {\n",
    "            'data_file': r'Fichier Data :\\s*(.*)',\n",
    "            'target_column': r'Colonne cible:\\s*(.*)',\n",
    "            'input_columns': r'Colonnes d\\'entree:\\s*(.*)',\n",
    "            'loss_function': r'Fonction de cout:\\s*(.*)',\n",
    "            'epochs': r'Nombre d\\'epoques:\\s*(\\d+)',\n",
    "            'layers': r'Nombre de couches:\\s*(\\d+)',\n",
    "            'neurons': r'Neurones par couche:\\s*(.*)',\n",
    "            'activation': r'Fonction d\\'activation:\\s*(.*)'\n",
    "        }\n",
    "\n",
    "        model_info = {}\n",
    "\n",
    "        with open(config_file, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Extract each piece of information using regex\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                if key == 'input_columns':\n",
    "                    model_info[key] = [col.strip() for col in match.group(1).split(',')]\n",
    "                elif key == 'neurons':\n",
    "                    model_info[key] = [int(neuron.strip()) for neuron in match.group(1).split(',')]\n",
    "                elif key in ['epochs', 'layers']:\n",
    "                    model_info[key] = int(match.group(1))  # Convertir en entier\n",
    "                else:\n",
    "                    model_info[key] = match.group(1).strip()\n",
    "\n",
    "        return model_info\n",
    "\n",
    "    def load_data(self):\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(self.model_info['data_file'])\n",
    "\n",
    "        # Identify categorical columns\n",
    "        categorical_cols = df[self.model_info['input_columns']].select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "        # Create a transformation pipeline\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', OneHotEncoder(), categorical_cols),  # Apply One-Hot Encoding to categorical columns\n",
    "            ],\n",
    "            remainder='passthrough'  # Keep other columns unchanged\n",
    "        )\n",
    "\n",
    "        # Split features and target\n",
    "        X = df[self.model_info['input_columns']]\n",
    "        y = df[self.model_info['target_column']].values\n",
    "\n",
    "        # Automatically detect the number of classes\n",
    "        self.num_classes = len(pd.unique(y))\n",
    "\n",
    "        # Label encode the target variable\n",
    "        label_encoder = LabelEncoder()\n",
    "        y = label_encoder.fit_transform(y)  # Convert species names to numeric labels\n",
    "\n",
    "        # One-Hot Encode the target if multi-class classification\n",
    "        if self.num_classes > 2:\n",
    "            y = tf.keras.utils.to_categorical(y, num_classes=self.num_classes)\n",
    "\n",
    "        # Apply transformations\n",
    "        X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "        # Split data into training and test sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Normalize the data\n",
    "        scaler = StandardScaler()\n",
    "        self.X_train = scaler.fit_transform(self.X_train)\n",
    "        self.X_test = scaler.transform(self.X_test)\n",
    "\n",
    "    def build_model(self):\n",
    "        # Créer le modèle ANN\n",
    "        self.model = tf.keras.Sequential()\n",
    "\n",
    "        # Ajouter les couches cachées\n",
    "        neurons = self.model_info['neurons']\n",
    "\n",
    "        for i in range(len(neurons)):\n",
    "            if i == 0:\n",
    "                # Première couche cachée\n",
    "                self.model.add(tf.keras.layers.Dense(units=neurons[i], activation=self.model_info['activation'], input_shape=(self.X_train.shape[1],)))\n",
    "            else:\n",
    "                # Couches cachées suivantes\n",
    "                self.model.add(tf.keras.layers.Dense(units=neurons[i], activation=self.model_info['activation']))\n",
    "\n",
    "        # Ajouter la couche de sortie\n",
    "        self.model.add(tf.keras.layers.Dense(units=1))  # Pour la régression, on a une sortie\n",
    "\n",
    "        # Compiler le modèle\n",
    "        self.model.compile(optimizer='adam', loss=self.model_info['loss_function'])\n",
    "\n",
    "    def train_model(self):\n",
    "        # Entraîner le modèle\n",
    "        self.history = self.model.fit(self.X_train, self.y_train, epochs=self.model_info['epochs'], batch_size=10, verbose=1, validation_split=0.2)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        # Évaluer le modèle\n",
    "        loss = self.model.evaluate(self.X_test, self.y_test)\n",
    "        print(f'Perte sur l\\'ensemble de test : {loss}')\n",
    "\n",
    "    matplotlib.use('Agg')\n",
    "    def plot_learning_curve(self):\n",
    "    # Create the 'assets/plots' directory if it doesn't exist\n",
    "        plots_dir = os.path.join('app','static', 'assets', 'plots')\n",
    "        os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "        # Check if the history contains the necessary keys\n",
    "        if 'loss' not in self.history.history or 'val_loss' not in self.history.history:\n",
    "            print(\"No loss data found in history. Plotting cannot be done.\")\n",
    "            return\n",
    "\n",
    "        # Plot the learning curves\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        try:\n",
    "            plt.plot(self.history.history['loss'], label='Perte d\\'entraînement', color='blue')\n",
    "            plt.plot(self.history.history['val_loss'], label='Perte de validation', color='orange')\n",
    "            plt.title('Courbe d\\'apprentissage')\n",
    "            plt.xlabel('Époques')\n",
    "            plt.ylabel('Perte')\n",
    "            plt.legend()\n",
    "            \n",
    "            # Save the plot in the 'assets/plots' directory\n",
    "            plot_path = os.path.join(plots_dir, 'learning_curve.png')\n",
    "            plt.savefig(plot_path)\n",
    "            print(f\"Learning curve saved at {plot_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while plotting the learning curve: {e}\")\n",
    "\n",
    "        finally:\n",
    "            # Clear the plot to free up memory\n",
    "            plt.clf()\n",
    "\n",
    "\n",
    "    def print_model_summary(self):\n",
    "        # Capture the model summary as a string\n",
    "        stream = StringIO()\n",
    "        self.model.summary(print_fn=lambda x: stream.write(x + '\\n'))\n",
    "        model_summary_str = stream.getvalue()\n",
    "\n",
    "        # Create a new figure for the summary\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.text(0, 1, model_summary_str, fontsize=10, ha='left', va='top', family='monospace')\n",
    "        plt.axis('off')  # Turn off the axis\n",
    "\n",
    "        # Define the paths for saving the summary image\n",
    "        plots_dir = os.path.join('app','static', 'assets', 'plots')\n",
    "        os.makedirs(plots_dir, exist_ok=True)\n",
    "        \n",
    "        # Save in the 'plots' directory\n",
    "        summary_image_path = os.path.join(plots_dir, 'model_summary.png')\n",
    "        plt.savefig(summary_image_path, bbox_inches='tight', pad_inches=0.1)\n",
    "        plt.close()  # Close the plot to free up memory\n",
    "\n",
    "        return summary_image_path  # Return the path to the saved image\n",
    "    \n",
    "    def save_regression_metrics_as_image(self):\n",
    "        # Generate predictions on the test set\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "\n",
    "        # Calculate regression metrics\n",
    "        mae = mean_absolute_error(self.y_test, y_pred)\n",
    "        mse = mean_squared_error(self.y_test, y_pred, squared=True)  # For Mean Squared Error\n",
    "        rmse = mean_squared_error(self.y_test, y_pred, squared=False)  # For Root Mean Squared Error\n",
    "\n",
    "        # Format the metrics as text\n",
    "        metrics_text = (\n",
    "            f\"Mean Absolute Error (MAE): {mae:.2f}\\n\"\n",
    "            f\"Mean Squared Error (MSE): {mse:.2f}\\n\"\n",
    "            f\"Root Mean Squared Error (RMSE): {rmse:.2f}\"\n",
    "        )\n",
    "        \n",
    "        # Set up the directory for saving plots\n",
    "        plots_dir = os.path.join('app', 'static', 'assets', 'plots')\n",
    "        os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "        # Create a figure for the metrics\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Display metrics as text\n",
    "        plt.text(0.5, 0.5, metrics_text, ha='center', va='center', fontsize=12, family='monospace')\n",
    "\n",
    "        # Save the metrics as an image\n",
    "        metrics_image_path = os.path.join(plots_dir, 'classification_report.png')\n",
    "        plt.savefig(metrics_image_path, bbox_inches='tight', pad_inches=0.5)\n",
    "        plt.close()  # Close the plot to free memory\n",
    "\n",
    "        print(f\"Regression metrics saved at {metrics_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANNRegressionModel('model_config.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
